####################
# Model
####################

# Cross-Encoder
entityrerankingcrossencodermodel = {
    # Model
    model_name = entityrerankingcrossencodermodel
    mention_context_length = 32
    max_n_candidates_in_training = 32
    max_n_candidates_in_inference = 16

    # Training
    adam_eps = 1e-6
    adam_weight_decay = 1e-2
    max_grad_norm = 1.0
    max_patience = 10
}

####################
# Model x Pretrained Language Model
####################

# Cross-Encoder x SciBERT (uncased)
entityrerankingcrossencodermodel_scibertuncased = ${entityrerankingcrossencodermodel}{
    # Pretrained
    bert_pretrained_name_or_path = allenai/scibert_scivocab_uncased
    max_seg_len = 512

    # Training
    bert_learning_rate = 2e-5
    task_learning_rate = 1e-4
}

####################
# Model x Pretrained Language Model x Dataset
####################

# Cross-Encoder x SciBERT (uncased) x CDR
entityrerankingcrossencodermodel_scibertuncased_cdr = ${entityrerankingcrossencodermodel_scibertuncased}{
    # Dataset
    dataset_name = cdr

    # Training
    max_epoch = 30
    batch_size = 1
    gradient_accumulation_steps = 1
    warmup_ratio = 0.01
    n_steps_for_monitoring = 20
    n_steps_for_validation = -1
}

